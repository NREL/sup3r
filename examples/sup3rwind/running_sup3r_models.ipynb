{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to run saved sup3r models on ERA5 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import xarray as xr\n",
    "import hvplot.xarray\n",
    "from rex import init_logger\n",
    "from sup3r.models import Sup3rGanWithObs\n",
    "from sup3r.preprocessing import DataHandler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "\n",
    "init_logger('sup3r', log_level='DEBUG')\n",
    "init_logger(__name__, log_level='DEBUG')\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-08 20:09:36,501 [base.py:180] : Loading GAN from disk in directory: /datasets/sup3rwind/models/experimental/15x_1x_14f_st_obs_unet_just_embed/gan_e1300\n",
      "INFO - 2025-04-08 20:09:36,502 [base.py:186] : Active python environment versions: \n",
      "{   'cftime': '1.6.4',\n",
      "    'dask': '2024.11.2',\n",
      "    'h5netcdf': '1.3.0',\n",
      "    'netCDF4': '1.6.5',\n",
      "    'nrel-phygnn': '0.0.30',\n",
      "    'nrel-rex': '0.2.99',\n",
      "    'numpy': '1.26.4',\n",
      "    'pandas': '2.2.2',\n",
      "    'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]',\n",
      "    'sklearn': '1.5.1',\n",
      "    'sup3r': '0.2.3.dev34+g9d6a51d2',\n",
      "    'tensorflow': '2.15.1',\n",
      "    'xarray': '2025.1.2'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-08 20:09:36,522 [abstract.py:403] : Loading model from disk that was created with the following package versions: \n",
      "{ 'cftime': '1.6.4',\n",
      "  'dask': '2024.11.2',\n",
      "  'h5netcdf': '1.3.0',\n",
      "  'netCDF4': '1.6.5',\n",
      "  'nrel-phygnn': '0.0.30',\n",
      "  'nrel-rex': '0.2.99',\n",
      "  'numpy': '1.26.4',\n",
      "  'pandas': '2.2.2',\n",
      "  'python': '3.11.9 (main, Apr 19 2024, 16:48:06) [GCC 11.2.0]',\n",
      "  'sklearn': '1.5.1',\n",
      "  'sup3r': '0.2.3.dev34+g9d6a51d2',\n",
      "  'tensorflow': '2.15.1',\n",
      "  'xarray': '2025.1.2'}\n"
     ]
    }
   ],
   "source": [
    "model_dir = '/datasets/sup3rwind/models/experimental/15x_1x_14f_st_obs_unet_just_embed/gan_e1300'\n",
    "model = Sup3rGanWithObs.load(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double check what the model needs as input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models take mainly low resolution data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature_2m',\n",
       " 'relativehumidity_2m',\n",
       " 'pressure_0m',\n",
       " 'ie',\n",
       " 'zust',\n",
       " 'slhf',\n",
       " 'sshf',\n",
       " 'd2m',\n",
       " 'cape',\n",
       " 'kx',\n",
       " 'i10fg',\n",
       " 'u_10m',\n",
       " 'v_10m',\n",
       " 'u_100m',\n",
       " 'v_100m',\n",
       " 'u_200m',\n",
       " 'v_200m',\n",
       " 'srl',\n",
       " 'sza',\n",
       " 'topography']"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lr_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models can also injest some high-resolution data (hr_exo_features)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['srl', 'sza', 'topography']"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hr_exo_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finaly, some models can also injest observation data which is mostly NaN except for sparse locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['u_10m', 'v_10m', 'temperature_2m', 'relativehumidity_2m', 'pressure_0m']"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.obs_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ok, so we need to load low-res data accordings to lr_features, and high-res data according to hr_exo_features and obs_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We'll use some of the high-resolution training data as a proxy for \"observation data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-08 20:09:49,906 [utilities.py:125] : Initialized DataHandler with:\n",
      "{ 'BaseLoader': None,\n",
      "  'FeatureRegistry': None,\n",
      "  'cache_kwargs': None,\n",
      "  'chunks': 'auto',\n",
      "  'features': [ 'temperature_2m',\n",
      "                'relativehumidity_2m',\n",
      "                'pressure_0m',\n",
      "                'ie',\n",
      "                'zust',\n",
      "                'slhf',\n",
      "                'sshf',\n",
      "                'd2m',\n",
      "                'cape',\n",
      "                'kx',\n",
      "                'i10fg',\n",
      "                'u_10m',\n",
      "                'v_10m',\n",
      "                'u_100m',\n",
      "                'v_100m',\n",
      "                'u_200m',\n",
      "                'v_200m',\n",
      "                'srl',\n",
      "                'sza',\n",
      "                'topography'],\n",
      "  'file_paths': '/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/lr*.h5',\n",
      "  'hr_spatial_coarsen': 1,\n",
      "  'interp_kwargs': None,\n",
      "  'load_features': 'all',\n",
      "  'nan_method_kwargs': None,\n",
      "  'res_kwargs': None,\n",
      "  'shape': None,\n",
      "  'target': None,\n",
      "  'threshold': None,\n",
      "  'time_roll': 0,\n",
      "  'time_shift': None,\n",
      "  'time_slice': slice(20, 30, None)}\n",
      "DEBUG - 2025-04-08 20:09:49,910 [utilities.py:129] : Memory usage is 153.263 GB out of 269.755 GB\n",
      "INFO - 2025-04-08 20:09:49,917 [utilities.py:125] : Initialized LoaderH5 with:\n",
      "{ 'BASE_LOADER': <class 'rex.resource_extraction.resource_extraction.MultiFileWindX'>,\n",
      "  'BaseLoader': None,\n",
      "  'chunks': 'auto',\n",
      "  'features': 'all',\n",
      "  'file_paths': '/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/lr*.h5',\n",
      "  'res_kwargs': None}\n",
      "DEBUG - 2025-04-08 20:09:49,917 [utilities.py:129] : Memory usage is 153.263 GB out of 269.755 GB\n",
      "DEBUG - 2025-04-08 20:09:55,351 [h5.py:174] : Rechunking features with chunks: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbenton/repos/rex/rex/resource.py:1287: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  datetime_index = pd.to_datetime(time_index.astype(str))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-08 20:09:56,403 [base.py:153] : Getting raster index for target / shape: None / None\n",
      "INFO - 2025-04-08 20:09:56,560 [base.py:224] : The distance between the closest coordinate: [  15.127 -104.881] and the requested target: [  15.127 -104.881] for files: ['/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_cape.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_d2m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_i10fg.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_ie.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_kx.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_lsm.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_pressure_0m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_pressure_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_relativehumidity_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_relativehumidity_2m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_skt.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_slhf.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_srl.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_sshf.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_sst.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_sza.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_temperature_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_temperature_2m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_topography.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_u_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_u_10m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_u_200m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_v_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_v_10m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_v_200m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/lr_zust.h5'] is 0.0.\n",
      "INFO - 2025-04-08 20:09:58,684 [base.py:131] : Rasterizing data for target / shape: [  15.127 -104.881] / [30 80]\n",
      "INFO - 2025-04-08 20:09:59,652 [utilities.py:125] : Initialized DataHandler with:\n",
      "{ 'BaseLoader': None,\n",
      "  'FeatureRegistry': None,\n",
      "  'cache_kwargs': None,\n",
      "  'chunks': 'auto',\n",
      "  'features': [ 'srl',\n",
      "                'sza',\n",
      "                'topography',\n",
      "                'u_10m',\n",
      "                'v_10m',\n",
      "                'temperature_2m',\n",
      "                'relativehumidity_2m',\n",
      "                'pressure_0m'],\n",
      "  'file_paths': '/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/hr*.h5',\n",
      "  'hr_spatial_coarsen': 1,\n",
      "  'interp_kwargs': None,\n",
      "  'load_features': 'all',\n",
      "  'nan_method_kwargs': None,\n",
      "  'res_kwargs': None,\n",
      "  'shape': None,\n",
      "  'target': None,\n",
      "  'threshold': None,\n",
      "  'time_roll': 0,\n",
      "  'time_shift': None,\n",
      "  'time_slice': slice(20, 30, None)}\n",
      "DEBUG - 2025-04-08 20:09:59,653 [utilities.py:129] : Memory usage is 153.014 GB out of 269.755 GB\n",
      "INFO - 2025-04-08 20:09:59,654 [utilities.py:125] : Initialized LoaderH5 with:\n",
      "{ 'BASE_LOADER': <class 'rex.resource_extraction.resource_extraction.MultiFileWindX'>,\n",
      "  'BaseLoader': None,\n",
      "  'chunks': 'auto',\n",
      "  'features': 'all',\n",
      "  'file_paths': '/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/hr*.h5',\n",
      "  'res_kwargs': None}\n",
      "DEBUG - 2025-04-08 20:09:59,655 [utilities.py:129] : Memory usage is 153.014 GB out of 269.755 GB\n",
      "DEBUG - 2025-04-08 20:09:59,725 [h5.py:174] : Rechunking features with chunks: auto\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bbenton/repos/rex/rex/resource.py:1287: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  datetime_index = pd.to_datetime(time_index.astype(str))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO - 2025-04-08 20:10:00,012 [base.py:153] : Getting raster index for target / shape: None / None\n",
      "INFO - 2025-04-08 20:10:00,069 [base.py:224] : The distance between the closest coordinate: [  14.996 -105.005] and the requested target: [  14.996 -105.005] for files: ['/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_pressure_0m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_relativehumidity_2m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_srl.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_sza.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_temperature_2m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_topography.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_10m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_120m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_160m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_200m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_40m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_u_80m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_100m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_10m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_120m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_160m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_200m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_40m.h5', '/datasets/sup3rwind/training_data/15x_to_2km_2011_15_-105_450x1200/hr_v_80m.h5'] is 0.0.\n",
      "INFO - 2025-04-08 20:10:00,263 [base.py:131] : Rasterizing data for target / shape: [  14.996 -105.005] / [ 450 1200]\n"
     ]
    }
   ],
   "source": [
    "lr_data = DataHandler('/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/lr*.h5', time_slice=slice(20, 30),\n",
    "                      features=model.lr_features)\n",
    "hr_data = DataHandler('/datasets/sup3rwind/training_data/15x_to_2km_2011_*450x1200*/hr*.h5', time_slice=slice(20, 30),\n",
    "                      features=model.hr_exo_features+[feat.replace('_obs', '') for feat in model.obs_features])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we need to pass the data to the model in the format it expects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The 'steps' list to accomodate possible multi-step models. 'combine_type' tells the model how to incorporate the exogenous data (e.g. whether it's part of a mid-network layer or incorporated as part of a multi-step forward pass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_input = lr_data.values[None, ...] # add batch dimension\n",
    "\n",
    "# simulate obs data by masking some of the high-res ground truth data\n",
    "onshore_mask = model._get_obs_mask(\n",
    "    np.zeros((1, *hr_data.shape[:-1])), spatial_frac=1e-4, time_frac=0.8)\n",
    "offshore_mask = model._get_obs_mask(\n",
    "    np.zeros((1, *hr_data.shape[:-1])), spatial_frac=1e-4, time_frac=0.5)\n",
    "mask = np.where(hr_data['topography'].isel(time=0).values[None] > 0,\n",
    "                onshore_mask, offshore_mask)\n",
    "\n",
    "exo_input = {}\n",
    "\n",
    "for feature in model.hr_exo_features + model.obs_features:\n",
    "    if feature in model.obs_features:\n",
    "        data = np.where(\n",
    "            mask[0, ..., None], np.nan,\n",
    "            hr_data[feature.replace('_obs', '')].values)\n",
    "    else:\n",
    "        data = hr_data[feature].values\n",
    "    exo_input[feature] = {\n",
    "        'steps': [\n",
    "            {'model': 0,\n",
    "             'combine_type': 'layer',\n",
    "             'data': data[None, ...][..., None],\n",
    "            }\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we can finally send the data through the model and generate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_output = model.generate(lr_input, exogenous_data=exo_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Double check ordering of output features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['temperature_2m',\n",
       " 'relativehumidity_2m',\n",
       " 'pressure_0m',\n",
       " 'u_10m',\n",
       " 'v_10m',\n",
       " 'u_40m',\n",
       " 'v_40m',\n",
       " 'u_80m',\n",
       " 'v_80m',\n",
       " 'u_100m',\n",
       " 'v_100m',\n",
       " 'u_120m',\n",
       " 'v_120m',\n",
       " 'u_160m',\n",
       " 'v_160m',\n",
       " 'u_200m',\n",
       " 'v_200m']"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.hr_out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = ('latitude', 'longitude', 'time')\n",
    "coords = {\n",
    "    'latitude': hr_data.latitude.values[:, 0],\n",
    "    'longitude': hr_data.longitude.values[0, :],\n",
    "    'time': hr_data.time\n",
    "}\n",
    "hr_out = xr.Dataset({feature: (dims, hr_output[0, ..., i]) for i, feature in enumerate(model.hr_out_features)})\n",
    "hr_out = hr_out.assign_coords(coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot windspeed at 10m and 100m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "hr_out['windspeed_10m'] = (dims, np.hypot(hr_out['u_10m'].values, hr_out['v_10m'].values))\n",
    "hr_out['windspeed_100m'] = (dims, np.hypot(hr_out['u_100m'].values, hr_out['v_100m'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b53e2b061b654627a7528931e92dcd89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'d9a0839b-df62-4939-8602-c3a67b9b838d': {'version…"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_out['windspeed_10m'].hvplot.quadmesh(\n",
    "    groupby='time', cmap='YlGnBu', clim=(0, 10),\n",
    "    rasterize=True,\n",
    "    widget_type=\"scrubber\",\n",
    "    widget_location=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eaad432ffa4db7b043814622287030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "BokehModel(combine_events=True, render_bundle={'docs_json': {'dfed3acb-d406-4da4-909c-791dfb300de2': {'version…"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_out['windspeed_100m'].hvplot.quadmesh(\n",
    "    groupby='time', cmap='YlGnBu', clim=(0, 10),\n",
    "    rasterize=True,\n",
    "    widget_type=\"scrubber\",\n",
    "    widget_location=\"bottom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sup3r",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
