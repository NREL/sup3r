# -*- coding: utf-8 -*-
"""SUP3R"""
import time
import logging
import pandas as pd
import tensorflow as tf
from tensorflow.keras.metrics import mean_squared_error
from phygnn import CustomNetwork, GradientUtils


logger = logging.getLogger(__name__)


class SpatioTemporalSup3r(GradientUtils):
    """Spatio Temporal Super Resolution GAN model."""

    def __init__(self, gen_layers, disc_t_layers, disc_s_layers):
        """
        Parameters
        ----------
        gen_layers : list | str
            Hidden layers input argument to phygnn.base.CustomNetwork for the
            generative super resolving model. Can also be a str filepath to a
            json config file containing the input layers argument.
        disc_t_layers : list | str
            Hidden layers input argument to phygnn.base.CustomNetwork for the
            discriminative temporal model. Can also be a str filepath to a json
            config file containing the input layers argument.
        disc_s_layers : list | str
            Hidden layers input argument to phygnn.base.CustomNetwork for the
            discriminative spatial model. Can also be a str filepath to a json
            config file containing the input layers argument.
        """

        self._history = None
        self._gen = CustomNetwork(hidden_layers=gen_layers, name='Generator')
        self._disc_t = CustomNetwork(hidden_layers=disc_t_layers,
                                     name='TemporalDiscriminator')
        self._disc_s = CustomNetwork(hidden_layers=disc_s_layers,
                                     name='SpatialDiscriminator')

    @property
    def generator(self):
        """Get the generative model.

        Returns
        -------
        phygnn.base.CustomNetwork
        """
        return self._gen

    @property
    def disc_spatial(self):
        """Get the spatial discriminator model.

        Returns
        -------
        phygnn.base.CustomNetwork
        """
        return self._disc_s

    @property
    def disc_temporal(self):
        """Get the temporal discriminator model.

        Returns
        -------
        phygnn.base.CustomNetwork
        """
        return self._disc_t

    @property
    def history(self):
        """
        Model training history DataFrame (None if not yet trained)

        Returns
        -------
        pandas.DataFrame | None
        """
        return self._history

    def calc_loss_gen(self, y_true, y_generated, y_disc_s, y_disc_t):
        """Calculate the loss term for the generator model.

        Parameters
        ----------
        y_true : tf.Tensor | np.ndarray
            Ground truth high resolution spatiotemporal data.
        y_generated : tf.Tensor
            Superresolved high resolution spatiotemporal data generated by the
            generative model.
        y_disc_s : tf.Tensor
            Raw discriminator outputs from the spatial discriminator model
            predicting only on y_generated (not on y_true).
        y_disc_t : tf.Tensor
            Raw discriminator outputs from the temporal discriminator model
            predicting only on y_generated (not on y_true).

        Returns
        -------
        loss_gen_s : tf.Tensor
            0D tensor generator model loss for the spatial component of the
            super resolution generated output. If self.alpha_advers==0, this is
            just the generator content loss.
        loss_gen_t : tf.Tensor
            0D tensor generator model loss for the temporal component of the
            super resolution generated output. If self.alpha_advers==0, this is
            just the generator content loss.
        """

        loss_gen_content = mean_squared_error(y_true, y_generated)
        loss_gen_content = tf.reduce_mean(loss_gen_content)
        loss_gen_s = loss_gen_content
        loss_gen_t = loss_gen_content
        if self.alpha_advers > 0:
            # note that these have flipped labels from the discriminator
            # loss because of the opposite optimization goal
            loss_disc_s_gen = tf.nn.sigmoid_cross_entropy_with_logits(
                logits=y_disc_s, labels=tf.ones_like(y_disc_s))
            loss_disc_t_gen = tf.nn.sigmoid_cross_entropy_with_logits(
                logits=y_disc_t, labels=tf.ones_like(y_disc_t))

            loss_gen_s += self.alpha_advers * tf.reduce_mean(loss_disc_s_gen)
            loss_gen_t += self.alpha_advers * tf.reduce_mean(loss_disc_t_gen)

        return loss_gen_s, loss_gen_t

    @staticmethod
    def calc_loss_disc(y_disc_true, y_disc_gen):
        """Calculate the loss term for the discriminator model (either the
        spatial or temporal discriminator).

        Parameters
        ----------
        y_disc_true : tf.Tensor
            Raw discriminator outputs from the discriminator model predicting
            only on y_true (not on y_generated).
        y_disc_gen : tf.Tensor
            Raw discriminator outputs from the discriminator model predicting
            only on y_generated (not on y_true).

        Returns
        -------
        loss_disc : tf.Tensor
            0D tensor discriminator model loss for either the spatial or
            temporal component of the super resolution generated output.
        """

        # note that these have flipped labels from the generator
        # loss because of the opposite optimization goal
        logits = tf.concat([y_disc_true, y_disc_gen], axis=0)
        labels = tf.concat([tf.ones_like(y_disc_true),
                            tf.zeros_like(y_disc_gen)], axis=0)

        loss_disc = tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,
                                                            labels=labels)
        loss_disc = tf.reduce_mean(loss_disc)

        return loss_disc

    def calc_loss(self, y_true, y_generated, weight_gen=1.0,
                  weight_disc_s=1.0, weight_disc_t=1.0):
        """Calculate the GAN loss function using generated and true high
        resolution data.

        Parameters
        ----------
        y_true : tf.Tensor | np.ndarray
            Ground truth high resolution spatiotemporal data.
        y_generated : tf.Tensor
            Superresolved high resolution spatiotemporal data generated by the
            generative model.
        weight_gen : bool
            Weight factor for the generative loss term in the loss function.
            This includes the generative content loss and the generative
            portion of the discriminator losses (both space and time).
        weight_disc_s : bool
            Weight factor for the spatial discriminator loss term in the loss
            function.
        weight_disc_t : bool
            Weight factor for the temporal discriminator loss term in the loss
            function.

        Returns
        -------
        loss_disc : tf.Tensor
            0D tensor representing the full GAN loss term. This can be a
            summation of up to four individual loss terms from the generative /
            discriminative models and for their respective spatial / temporal
            components or models.
        """

        loss_gen_s = tf.constant(0.0, dtype=tf.float32)
        loss_gen_t = tf.constant(0.0, dtype=tf.float32)
        loss_disc_s = tf.constant(0.0, dtype=tf.float32)
        loss_disc_t = tf.constant(0.0, dtype=tf.float32)

        y_disc_s_true = self.disc_spatial.predict(y_true)
        y_disc_t_true = self.disc_temporal.predict(y_true)
        y_disc_s_gen = self.disc_spatial.predict(y_generated)
        y_disc_t_gen = self.disc_temporal.predict(y_generated)

        if weight_gen > 0:
            loss_gen_s, loss_gen_t = self.calc_loss_gen(y_true, y_generated,
                                                        y_disc_s_gen,
                                                        y_disc_t_gen)

        if weight_disc_s > 0:
            loss_disc_s = self.calc_loss_disc(y_disc_s_true, y_disc_s_gen)

        if weight_disc_t > 0:
            loss_disc_t = self.calc_loss_disc(y_disc_t_true, y_disc_t_gen)

        loss = (weight_gen * (loss_gen_s + loss_gen_t)
                + weight_disc_s * loss_disc_s
                + weight_disc_t * loss_disc_t)

        return loss

    def train(self, x, y, n_batch=16, n_epoch=100, shuffle=True,
              validation_split=0.1, return_diagnostics=False):
        """Train the GAN model on real low res data x and real high res data y

        Parameters
        ----------
        x : np.ndarray
            Real low-resolution data in a 5D array:
            (n_observations, spatial_1, spatial_2, temporal, features)
        y : np.ndarray
            Real high-resolution data in a 5D array:
            (n_observations, spatial_1, spatial_2, temporal, features)
        n_batch : int
            Number of times to update the weights per epoch (number of
            mini-batches). The training data will be split into this many
            mini-batches and the NN will train on each mini-batch, update
            weights, then move onto the next mini-batch.
        n_epoch : int
            Number of times to iterate on the training data.
        shuffle : bool
            Flag to randomly subset the validation data and batch selection
            from x, y, and p.
        validation_split : float
            Fraction of x, y, and p to use for validation.
        return_diagnostics : bool
            Flag to return training diagnostics dictionary.

        Returns
        -------
        diagnostics : dict
            Namespace of training parameters that can be used for diagnostics.
        """
        epochs = list(range(n_epoch))

        if self._history is None:
            self._history = pd.DataFrame(
                columns=['elapsed_time',
                         'training_loss',
                         'validation_loss',
                         ])
            self._history.index.name = 'epoch'
        else:
            epochs += self._history.index.values[-1] + 1

        x, y, x_val, y_val = self.get_val_split(
            x, y, shuffle=shuffle, validation_split=validation_split)

        tr_loss = None
        t0 = time.time()
        for epoch in epochs:

            batch_iter = self.make_batches(x, y, n_batch=n_batch,
                                           shuffle=shuffle)

            for x_batch, y_batch in batch_iter:
                tr_loss = self.run_gradient_descent(x_batch, y_batch)

            y_val_gen = self.generator.predict(x_val, to_numpy=False)
            val_loss = self.calc_loss(y_val, y_val_gen)
            logger.info('Epoch {} train loss: {:.2e} '
                        'val loss: {:.2e} for "{}"'
                        .format(epoch, tr_loss, val_loss, self.name))

            self._history.at[epoch, 'elapsed_time'] = time.time() - t0
            self._history.at[epoch, 'training_loss'] = tr_loss.numpy()
            self._history.at[epoch, 'validation_loss'] = val_loss.numpy()

        diagnostics = {'x': x, 'y': y, 'x_val': x_val, 'y_val': y_val,
                       'history': self.history,
                       }

        if return_diagnostics:
            return diagnostics
